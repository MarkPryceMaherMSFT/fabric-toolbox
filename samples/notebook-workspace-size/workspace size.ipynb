{"cells":[{"cell_type":"code","source":["from notebookutils import mssparkutils\n","\n","def scan_folder(folder,total_size):\n","    #print(f\" folder = {folder}\")\n","    l0 = notebookutils.fs.ls(folder)\n","    for l1 in l0:\n","        if l1.isDir==False:\n","             #print(f\" name = {l1.name} : {l1.size/ 1024/1024:.2f} MB\")\n","             total_size = total_size + l1.size\n","    \n","    for l1 in l0:    \n","        if l1.isDir:\n","            dirsize = scan_folder(l1.path,  0);\n","            #print(f\"{l1.path} : {dirsize/ 1024/1024:.2f} MB\")\n","            total_size = total_size + dirsize\n"," \n","    return total_size\n","\n","total_size=0.00;\n","\n","# Warehouse\n","#delta_table_path = f\"abfss://[workspace]@onelake.dfs.fabric.microsoft.com/[warehouse name].Datawarehouse/dbo/[table name]\"\n","\n","# lakehouse\n","#delta_table_path = \"abfss://[workspace]@onelake.dfs.fabric.microsoft.com/[lakehouse name].Lakehouse/Tables/[table name]\"\n","\n","# Workspace\n","delta_table_path = \"abfss://[workspace]@onelake.dfs.fabric.microsoft.com/\"\n","\n","total_size = scan_folder(delta_table_path, total_size)\n","total_size = total_size/ 1024/1024\n","print(f\"  Total Workspace Size: {total_size:.2f} MB\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"377c1f19-92bc-4562-a8de-f9088a4ee999"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}