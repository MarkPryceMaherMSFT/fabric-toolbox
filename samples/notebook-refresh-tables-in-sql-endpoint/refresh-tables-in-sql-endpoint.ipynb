{"cells":[{"cell_type":"code","source":["########################################################################################################\n","# Sample script to call the syncronisation between the Fabric Lakehouse and the SQL Endpoint\n","#        \n","## THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n","#\n","#  This script is a workaround until the documented API is released: https://learn.microsoft.com/en-us/fabric/release-plan/data-warehouse#refresh-sql-analytics-endpoint-rest-api\n","#\n","#sempy version 0.4.0 or higher\n","!pip install semantic-link --q \n","import json\n","import time\n","import struct\n","import sqlalchemy\n","import pyodbc\n","import notebookutils\n","import pandas as pd\n","from pyspark.sql import functions as fn\n","from datetime import datetime\n","import sempy.fabric as fabric\n","from sempy.fabric.exceptions import FabricHTTPException, WorkspaceNotFoundException\n","\n","def pad_or_truncate_string(input_string, length, pad_char=' '):\n","    # Truncate if the string is longer than the specified length\n","    if len(input_string) > length:\n","        return input_string[:length]\n","    # Pad if the string is shorter than the specified length\n","    return input_string.ljust(length, pad_char)\n","\n","## not needed, but usefull\n","tenant_id=spark.conf.get(\"trident.tenant.id\")\n","workspace_id=spark.conf.get(\"trident.workspace.id\")\n","lakehouse_id=spark.conf.get(\"trident.lakehouse.id\")\n","lakehouse_name=spark.conf.get(\"trident.lakehouse.name\")\n","#sql_endpoint= fabric.FabricRestClient().get(f\"/v1/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\").json()['properties']['sqlEndpointProperties']['connectionString']\n","\n","#Instantiate the client\n","client = fabric.FabricRestClient()\n","\n","# This is the SQL endpoint I want to sync with the lakehouse, this needs to be the GUI\n","sqlendpoint = fabric.FabricRestClient().get(f\"/v1/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\").json()['properties']['sqlEndpointProperties']['id']\n","j_son = fabric.FabricRestClient().get(f\"/v1/workspaces/{workspace_id}/lakehouses/{lakehouse_id}\").json()\n","#display(j_son)\n","\n","# URI for the call\n","uri = f\"/v1.0/myorg/lhdatamarts/{sqlendpoint}\"\n","# This is the action, we want to take\n","payload = {\"commands\":[{\"$type\":\"MetadataRefreshExternalCommand\"}]}\n","\n","# code for testing \n","# Test 1 : test creating a new table\n","#spark.sql(\"drop table if exists test1\")\n","#spark.sql(\"create table test1 as SELECT * FROM lakehouse.Date LIMIT 1000\")\n","# Test 2 : create a duplicate of the table with a different case\n","#df = spark.sql(\"SELECT * FROM lakehouse.Date LIMIT 1000\")\n","#df.write.save(\"Tables/Test1\")\n","\n","# Call the REST API\n","response = client.post(uri,json= payload)\n","## You should add some error handling here\n","\n","# return the response from json into an object we can get values from\n","data = json.loads(response.text)\n","\n","# We just need this, we pass this to call to check the status\n","batchId = data[\"batchId\"]\n","\n","# the state of the sync i.e. inProgress\n","progressState = data[\"progressState\"]\n","\n","# URL so we can get the status of the sync\n","statusuri = f\"/v1.0/myorg/lhdatamarts/{sqlendpoint}/batches/{batchId}\"\n","\n","statusresponsedata = \"\"\n","\n","while progressState == 'inProgress' :\n","    # For the demo, I have removed the 1 second sleep.\n","    time.sleep(1)\n","\n","    # check to see if its sync'ed\n","    #statusresponse = client.get(statusuri)\n","\n","    # turn response into object\n","    statusresponsedata = client.get(statusuri).json()\n","\n","    # get the status of the check\n","    progressState = statusresponsedata[\"progressState\"]\n","    # show the status\n","    display(f\"Sync state: {progressState}\")\n","\n","# if its good, then create a temp results, with just the info we care about\n","if progressState == 'success':\n","    table_details = [\n","        {\n","          'tableName': table['tableName'],\n","         'warningMessages': table.get('warningMessages', []),\n","         'lastSuccessfulUpdate': table.get('lastSuccessfulUpdate', 'N/A'),\n","         'tableSyncState':  table['tableSyncState'],\n","         'sqlSyncState':  table['sqlSyncState']\n","        }\n","        for table in statusresponsedata['operationInformation'][0]['progressDetail']['tablesSyncStatus']\n","    ]\n","\n","# if its good, then shows the tables\n","if progressState == 'success':\n","    # Print the extracted details\n","    print(\"Extracted Table Details:\")\n","    for detail in table_details:\n","        print(f\"Table: {pad_or_truncate_string(detail['tableName'],30)}   Last Update: {detail['lastSuccessfulUpdate']}  tableSyncState: {detail['tableSyncState']}   Warnings: {detail['warningMessages']}\")\n","\n","## if there is a problem, show all the errors\n","if progressState == 'failure':\n","    # display error if there is an error\n","    display(statusresponsedata)\n","    "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b3081c8e-ed99-4f4d-887e-52005084186a"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"5b489503-4b3b-4fe3-aef7-ac8bdf09211e","known_lakehouses":[{"id":"5b489503-4b3b-4fe3-aef7-ac8bdf09211e"}],"default_lakehouse_name":"Backup_LH","default_lakehouse_workspace_id":"be3544c2-423d-46f9-b8bc-50b7c1fd7296"}}},"nbformat":4,"nbformat_minor":5}